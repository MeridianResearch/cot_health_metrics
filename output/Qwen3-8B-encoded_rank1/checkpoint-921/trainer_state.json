{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 921,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03257328990228013,
      "grad_norm": 252.16375732421875,
      "learning_rate": 1.168831168831169e-06,
      "loss": 4.9374,
      "step": 10
    },
    {
      "epoch": 0.06514657980456026,
      "grad_norm": 97.28551483154297,
      "learning_rate": 2.4675324675324676e-06,
      "loss": 3.9326,
      "step": 20
    },
    {
      "epoch": 0.09771986970684039,
      "grad_norm": 22.48785400390625,
      "learning_rate": 3.7662337662337666e-06,
      "loss": 3.0405,
      "step": 30
    },
    {
      "epoch": 0.13029315960912052,
      "grad_norm": 22.077709197998047,
      "learning_rate": 5.064935064935065e-06,
      "loss": 2.5386,
      "step": 40
    },
    {
      "epoch": 0.16286644951140064,
      "grad_norm": 28.06684684753418,
      "learning_rate": 6.363636363636364e-06,
      "loss": 2.2838,
      "step": 50
    },
    {
      "epoch": 0.19543973941368079,
      "grad_norm": 35.633609771728516,
      "learning_rate": 7.662337662337663e-06,
      "loss": 1.8988,
      "step": 60
    },
    {
      "epoch": 0.2280130293159609,
      "grad_norm": 29.50445556640625,
      "learning_rate": 8.96103896103896e-06,
      "loss": 1.5977,
      "step": 70
    },
    {
      "epoch": 0.26058631921824105,
      "grad_norm": 28.836402893066406,
      "learning_rate": 1.025974025974026e-05,
      "loss": 1.3836,
      "step": 80
    },
    {
      "epoch": 0.2931596091205212,
      "grad_norm": 22.961820602416992,
      "learning_rate": 1.155844155844156e-05,
      "loss": 1.2979,
      "step": 90
    },
    {
      "epoch": 0.3257328990228013,
      "grad_norm": 23.274866104125977,
      "learning_rate": 1.2857142857142859e-05,
      "loss": 1.1023,
      "step": 100
    },
    {
      "epoch": 0.3583061889250814,
      "grad_norm": 23.001588821411133,
      "learning_rate": 1.4155844155844157e-05,
      "loss": 1.0718,
      "step": 110
    },
    {
      "epoch": 0.39087947882736157,
      "grad_norm": 22.276561737060547,
      "learning_rate": 1.5454545454545454e-05,
      "loss": 0.966,
      "step": 120
    },
    {
      "epoch": 0.4234527687296417,
      "grad_norm": 18.724475860595703,
      "learning_rate": 1.6753246753246756e-05,
      "loss": 0.9104,
      "step": 130
    },
    {
      "epoch": 0.4560260586319218,
      "grad_norm": 27.511959075927734,
      "learning_rate": 1.8051948051948053e-05,
      "loss": 0.8374,
      "step": 140
    },
    {
      "epoch": 0.48859934853420195,
      "grad_norm": 24.720609664916992,
      "learning_rate": 1.9350649350649354e-05,
      "loss": 0.7575,
      "step": 150
    },
    {
      "epoch": 0.5211726384364821,
      "grad_norm": 23.429750442504883,
      "learning_rate": 1.9999353128944386e-05,
      "loss": 0.6756,
      "step": 160
    },
    {
      "epoch": 0.5537459283387622,
      "grad_norm": 20.776611328125,
      "learning_rate": 1.9994178662619237e-05,
      "loss": 0.6701,
      "step": 170
    },
    {
      "epoch": 0.5863192182410424,
      "grad_norm": 17.9052791595459,
      "learning_rate": 1.9983832407652323e-05,
      "loss": 0.6295,
      "step": 180
    },
    {
      "epoch": 0.6188925081433225,
      "grad_norm": 18.296236038208008,
      "learning_rate": 1.9968319718024776e-05,
      "loss": 0.6208,
      "step": 190
    },
    {
      "epoch": 0.6514657980456026,
      "grad_norm": 17.020713806152344,
      "learning_rate": 1.994764862124487e-05,
      "loss": 0.607,
      "step": 200
    },
    {
      "epoch": 0.6840390879478827,
      "grad_norm": 20.235633850097656,
      "learning_rate": 1.9921829814193987e-05,
      "loss": 0.6055,
      "step": 210
    },
    {
      "epoch": 0.7166123778501629,
      "grad_norm": 20.4251766204834,
      "learning_rate": 1.9890876657591146e-05,
      "loss": 0.59,
      "step": 220
    },
    {
      "epoch": 0.749185667752443,
      "grad_norm": 17.84681510925293,
      "learning_rate": 1.9854805169079142e-05,
      "loss": 0.5492,
      "step": 230
    },
    {
      "epoch": 0.7817589576547231,
      "grad_norm": 20.34191131591797,
      "learning_rate": 1.9813634014935697e-05,
      "loss": 0.6009,
      "step": 240
    },
    {
      "epoch": 0.8143322475570033,
      "grad_norm": 21.223358154296875,
      "learning_rate": 1.9767384500414054e-05,
      "loss": 0.5443,
      "step": 250
    },
    {
      "epoch": 0.8469055374592834,
      "grad_norm": 16.601150512695312,
      "learning_rate": 1.971608055871793e-05,
      "loss": 0.613,
      "step": 260
    },
    {
      "epoch": 0.8794788273615635,
      "grad_norm": 19.705947875976562,
      "learning_rate": 1.965974873861655e-05,
      "loss": 0.572,
      "step": 270
    },
    {
      "epoch": 0.9120521172638436,
      "grad_norm": 20.08797264099121,
      "learning_rate": 1.95984181907062e-05,
      "loss": 0.5476,
      "step": 280
    },
    {
      "epoch": 0.9446254071661238,
      "grad_norm": 18.425168991088867,
      "learning_rate": 1.9532120652325362e-05,
      "loss": 0.5688,
      "step": 290
    },
    {
      "epoch": 0.9771986970684039,
      "grad_norm": 19.6461238861084,
      "learning_rate": 1.946089043113128e-05,
      "loss": 0.5349,
      "step": 300
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.507222056388855,
      "eval_runtime": 12.2297,
      "eval_samples_per_second": 7.277,
      "eval_steps_per_second": 7.277,
      "step": 307
    },
    {
      "epoch": 1.009771986970684,
      "grad_norm": 15.749368667602539,
      "learning_rate": 1.938476438734642e-05,
      "loss": 0.4902,
      "step": 310
    },
    {
      "epoch": 1.0423452768729642,
      "grad_norm": 16.850902557373047,
      "learning_rate": 1.9303781914684057e-05,
      "loss": 0.5169,
      "step": 320
    },
    {
      "epoch": 1.0749185667752443,
      "grad_norm": 18.807693481445312,
      "learning_rate": 1.921798491996279e-05,
      "loss": 0.5069,
      "step": 330
    },
    {
      "epoch": 1.1074918566775245,
      "grad_norm": 14.197159767150879,
      "learning_rate": 1.912741780142061e-05,
      "loss": 0.4598,
      "step": 340
    },
    {
      "epoch": 1.1400651465798046,
      "grad_norm": 15.896628379821777,
      "learning_rate": 1.9032127425739695e-05,
      "loss": 0.512,
      "step": 350
    },
    {
      "epoch": 1.1726384364820848,
      "grad_norm": 14.960968017578125,
      "learning_rate": 1.8932163103793832e-05,
      "loss": 0.4986,
      "step": 360
    },
    {
      "epoch": 1.205211726384365,
      "grad_norm": 14.70835018157959,
      "learning_rate": 1.882757656513101e-05,
      "loss": 0.4588,
      "step": 370
    },
    {
      "epoch": 1.237785016286645,
      "grad_norm": 20.98525047302246,
      "learning_rate": 1.871842193120444e-05,
      "loss": 0.4814,
      "step": 380
    },
    {
      "epoch": 1.2703583061889252,
      "grad_norm": 21.195186614990234,
      "learning_rate": 1.8604755687365728e-05,
      "loss": 0.4821,
      "step": 390
    },
    {
      "epoch": 1.3029315960912053,
      "grad_norm": 19.49863624572754,
      "learning_rate": 1.848663665363489e-05,
      "loss": 0.4711,
      "step": 400
    },
    {
      "epoch": 1.3355048859934853,
      "grad_norm": 18.59563636779785,
      "learning_rate": 1.8364125954262112e-05,
      "loss": 0.4632,
      "step": 410
    },
    {
      "epoch": 1.3680781758957654,
      "grad_norm": 16.981237411499023,
      "learning_rate": 1.823728698609719e-05,
      "loss": 0.4732,
      "step": 420
    },
    {
      "epoch": 1.4006514657980456,
      "grad_norm": 16.530620574951172,
      "learning_rate": 1.8106185385782916e-05,
      "loss": 0.4857,
      "step": 430
    },
    {
      "epoch": 1.4332247557003257,
      "grad_norm": 15.553412437438965,
      "learning_rate": 1.7970888995789427e-05,
      "loss": 0.5008,
      "step": 440
    },
    {
      "epoch": 1.4657980456026058,
      "grad_norm": 17.767431259155273,
      "learning_rate": 1.783146782930706e-05,
      "loss": 0.4826,
      "step": 450
    },
    {
      "epoch": 1.498371335504886,
      "grad_norm": 15.902400016784668,
      "learning_rate": 1.7687994034015943e-05,
      "loss": 0.492,
      "step": 460
    },
    {
      "epoch": 1.5309446254071661,
      "grad_norm": 15.694785118103027,
      "learning_rate": 1.7540541854750984e-05,
      "loss": 0.469,
      "step": 470
    },
    {
      "epoch": 1.5635179153094463,
      "grad_norm": 15.2349853515625,
      "learning_rate": 1.738918759508166e-05,
      "loss": 0.4801,
      "step": 480
    },
    {
      "epoch": 1.5960912052117264,
      "grad_norm": 16.28590202331543,
      "learning_rate": 1.7234009577826428e-05,
      "loss": 0.5097,
      "step": 490
    },
    {
      "epoch": 1.6286644951140063,
      "grad_norm": 15.411308288574219,
      "learning_rate": 1.7075088104522235e-05,
      "loss": 0.4452,
      "step": 500
    },
    {
      "epoch": 1.6612377850162865,
      "grad_norm": 13.670369148254395,
      "learning_rate": 1.6912505413870054e-05,
      "loss": 0.5032,
      "step": 510
    },
    {
      "epoch": 1.6938110749185666,
      "grad_norm": 15.885871887207031,
      "learning_rate": 1.6746345639178013e-05,
      "loss": 0.4526,
      "step": 520
    },
    {
      "epoch": 1.7263843648208468,
      "grad_norm": 14.363598823547363,
      "learning_rate": 1.657669476482407e-05,
      "loss": 0.4744,
      "step": 530
    },
    {
      "epoch": 1.758957654723127,
      "grad_norm": 14.62663459777832,
      "learning_rate": 1.640364058176079e-05,
      "loss": 0.4905,
      "step": 540
    },
    {
      "epoch": 1.791530944625407,
      "grad_norm": 16.907697677612305,
      "learning_rate": 1.6227272642085326e-05,
      "loss": 0.4659,
      "step": 550
    },
    {
      "epoch": 1.8241042345276872,
      "grad_norm": 13.50130558013916,
      "learning_rate": 1.6047682212697925e-05,
      "loss": 0.4531,
      "step": 560
    },
    {
      "epoch": 1.8566775244299674,
      "grad_norm": 14.894065856933594,
      "learning_rate": 1.586496222807318e-05,
      "loss": 0.4786,
      "step": 570
    },
    {
      "epoch": 1.8892508143322475,
      "grad_norm": 15.265202522277832,
      "learning_rate": 1.5679207242168234e-05,
      "loss": 0.4644,
      "step": 580
    },
    {
      "epoch": 1.9218241042345277,
      "grad_norm": 17.756942749023438,
      "learning_rate": 1.549051337949305e-05,
      "loss": 0.4655,
      "step": 590
    },
    {
      "epoch": 1.9543973941368078,
      "grad_norm": 15.96093463897705,
      "learning_rate": 1.5298978285367826e-05,
      "loss": 0.4766,
      "step": 600
    },
    {
      "epoch": 1.986970684039088,
      "grad_norm": 13.340731620788574,
      "learning_rate": 1.510470107539353e-05,
      "loss": 0.4502,
      "step": 610
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.47416096925735474,
      "eval_runtime": 12.2207,
      "eval_samples_per_second": 7.283,
      "eval_steps_per_second": 7.283,
      "step": 614
    },
    {
      "epoch": 2.019543973941368,
      "grad_norm": 21.967151641845703,
      "learning_rate": 1.4907782284161531e-05,
      "loss": 0.3819,
      "step": 620
    },
    {
      "epoch": 2.0521172638436482,
      "grad_norm": 19.451026916503906,
      "learning_rate": 1.4708323813228949e-05,
      "loss": 0.3511,
      "step": 630
    },
    {
      "epoch": 2.0846905537459284,
      "grad_norm": 16.318830490112305,
      "learning_rate": 1.4506428878386623e-05,
      "loss": 0.3735,
      "step": 640
    },
    {
      "epoch": 2.1172638436482085,
      "grad_norm": 19.016883850097656,
      "learning_rate": 1.4302201956247e-05,
      "loss": 0.38,
      "step": 650
    },
    {
      "epoch": 2.1498371335504887,
      "grad_norm": 23.61890411376953,
      "learning_rate": 1.4095748730179559e-05,
      "loss": 0.3588,
      "step": 660
    },
    {
      "epoch": 2.182410423452769,
      "grad_norm": 20.315141677856445,
      "learning_rate": 1.3887176035621777e-05,
      "loss": 0.3669,
      "step": 670
    },
    {
      "epoch": 2.214983713355049,
      "grad_norm": 17.763628005981445,
      "learning_rate": 1.367659180479391e-05,
      "loss": 0.3538,
      "step": 680
    },
    {
      "epoch": 2.247557003257329,
      "grad_norm": 19.86139488220215,
      "learning_rate": 1.3464105010846222e-05,
      "loss": 0.3399,
      "step": 690
    },
    {
      "epoch": 2.2801302931596092,
      "grad_norm": 17.4810848236084,
      "learning_rate": 1.3249825611467535e-05,
      "loss": 0.3458,
      "step": 700
    },
    {
      "epoch": 2.3127035830618894,
      "grad_norm": 18.634437561035156,
      "learning_rate": 1.3033864491984324e-05,
      "loss": 0.3771,
      "step": 710
    },
    {
      "epoch": 2.3452768729641695,
      "grad_norm": 18.266103744506836,
      "learning_rate": 1.2816333407979775e-05,
      "loss": 0.3708,
      "step": 720
    },
    {
      "epoch": 2.3778501628664497,
      "grad_norm": 18.855257034301758,
      "learning_rate": 1.259734492746246e-05,
      "loss": 0.3731,
      "step": 730
    },
    {
      "epoch": 2.41042345276873,
      "grad_norm": 20.528955459594727,
      "learning_rate": 1.2377012372614676e-05,
      "loss": 0.3674,
      "step": 740
    },
    {
      "epoch": 2.44299674267101,
      "grad_norm": 19.469402313232422,
      "learning_rate": 1.2155449761150431e-05,
      "loss": 0.3823,
      "step": 750
    },
    {
      "epoch": 2.47557003257329,
      "grad_norm": 21.082387924194336,
      "learning_rate": 1.1932771747313574e-05,
      "loss": 0.3552,
      "step": 760
    },
    {
      "epoch": 2.5081433224755703,
      "grad_norm": 18.55885124206543,
      "learning_rate": 1.1709093562546483e-05,
      "loss": 0.3642,
      "step": 770
    },
    {
      "epoch": 2.5407166123778504,
      "grad_norm": 18.56386947631836,
      "learning_rate": 1.148453095586011e-05,
      "loss": 0.3927,
      "step": 780
    },
    {
      "epoch": 2.5732899022801305,
      "grad_norm": 17.3785457611084,
      "learning_rate": 1.1259200133936142e-05,
      "loss": 0.3585,
      "step": 790
    },
    {
      "epoch": 2.6058631921824107,
      "grad_norm": 19.13262176513672,
      "learning_rate": 1.1033217700992373e-05,
      "loss": 0.3448,
      "step": 800
    },
    {
      "epoch": 2.6384364820846904,
      "grad_norm": 22.656635284423828,
      "learning_rate": 1.0806700598442343e-05,
      "loss": 0.3622,
      "step": 810
    },
    {
      "epoch": 2.6710097719869705,
      "grad_norm": 20.519161224365234,
      "learning_rate": 1.0579766044380473e-05,
      "loss": 0.3705,
      "step": 820
    },
    {
      "epoch": 2.7035830618892507,
      "grad_norm": 18.810272216796875,
      "learning_rate": 1.0352531472924035e-05,
      "loss": 0.3271,
      "step": 830
    },
    {
      "epoch": 2.736156351791531,
      "grad_norm": 24.193113327026367,
      "learning_rate": 1.0125114473443332e-05,
      "loss": 0.3623,
      "step": 840
    },
    {
      "epoch": 2.768729641693811,
      "grad_norm": 17.487024307250977,
      "learning_rate": 9.897632729711553e-06,
      "loss": 0.3753,
      "step": 850
    },
    {
      "epoch": 2.801302931596091,
      "grad_norm": 21.188617706298828,
      "learning_rate": 9.670203959005733e-06,
      "loss": 0.3611,
      "step": 860
    },
    {
      "epoch": 2.8338762214983713,
      "grad_norm": 21.402679443359375,
      "learning_rate": 9.442945851190433e-06,
      "loss": 0.3452,
      "step": 870
    },
    {
      "epoch": 2.8664495114006514,
      "grad_norm": 15.506099700927734,
      "learning_rate": 9.215976007815553e-06,
      "loss": 0.355,
      "step": 880
    },
    {
      "epoch": 2.8990228013029316,
      "grad_norm": 20.053592681884766,
      "learning_rate": 8.989411881259888e-06,
      "loss": 0.3552,
      "step": 890
    },
    {
      "epoch": 2.9315960912052117,
      "grad_norm": 21.539634704589844,
      "learning_rate": 8.763370713951841e-06,
      "loss": 0.3416,
      "step": 900
    },
    {
      "epoch": 2.964169381107492,
      "grad_norm": 17.506500244140625,
      "learning_rate": 8.537969477698822e-06,
      "loss": 0.3416,
      "step": 910
    },
    {
      "epoch": 2.996742671009772,
      "grad_norm": 20.138526916503906,
      "learning_rate": 8.313324813156633e-06,
      "loss": 0.3911,
      "step": 920
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.4933302402496338,
      "eval_runtime": 12.1828,
      "eval_samples_per_second": 7.305,
      "eval_steps_per_second": 7.305,
      "step": 921
    }
  ],
  "logging_steps": 10,
  "max_steps": 1535,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.7053707027022848e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
